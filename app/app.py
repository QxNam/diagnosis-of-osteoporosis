import gradio as gr
import numpy as np
from utils import enhance_xray, extract_roi, predict_cls, segment_roi
import cv2

def process_and_classify(raw_image: np.ndarray, processing_mode: str, model_choice: str):
    if raw_image is None:
        return None, None, None, "Vui l√≤ng t·∫£i ·∫£nh l√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu."

    # if processing_mode != "ROI Extract":
    #     return raw_image, raw_image, raw_image, "Ch·ªâ h·ªó tr·ª£ Simple ROI trong phi√™n b·∫£n n√†y."

    # Tr√≠ch xu·∫•t ROI
    rois_draw, rois = extract_roi(image=raw_image)
    if not rois:
        return raw_image, rois_draw, None, "Kh√¥ng t√¨m th·∫•y ROI n√†o."
    
    # TƒÉng c∆∞·ªùng ·∫£nh
    enhanceds = []
    for roi in rois:
        if processing_mode.lower() == "segment":
            roi = segment_roi(roi)
        if not isinstance(roi, np.ndarray):
            roi = np.array(roi)
        if len(roi.shape) == 3 and roi.shape[2] == 3:
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
        else:
            gray = roi.copy()
        enhanced = enhance_xray(image=gray)
        enhanceds.append(enhanced)
    # D·ª± ƒëo√°n k·∫øt qu·∫£
    predictions, transformed_images = predict_cls(model_choice.lower(), enhanceds)

    # D·ª± ƒëo√°n k·∫øt qu·∫£
    results = []
    for i, pred in enumerate(predictions):
        print(f'üü¢ ROI {i}, predict: {pred}')
        result_str = {
            pred[0]: pred[1]
        }
        results.append(result_str)
    if len(enhanceds)==1:
        return rois_draw, transformed_images[0], None, results[0], None
    return rois_draw, transformed_images[0], transformed_images[1], results[0], results[1]

# def process_and_classify(raw_image: np.ndarray, processing_mode: str, model_choice: str):
#     return None, None, None, None, None

# --- X√ÇY D·ª∞NG GIAO DI·ªÜN GRADIO ---

with gr.Blocks(theme=gr.themes.Soft(), title="Ph√¢n lo·∫°i ·∫£nh X-quang") as app:
    gr.Markdown(
        """
        # ·ª®ng d·ª•ng Ph√¢n lo·∫°i ·∫¢nh Y t·∫ø X-quang
        T·∫£i l√™n m·ªôt ·∫£nh X-quang, ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω, ch·ªçn m√¥ h√¨nh v√† xem k·∫øt qu·∫£.
        """
    )

    with gr.Row():
        # C·ªôt b√™n tr√°i cho input
        with gr.Column(scale=1):
            input_image = gr.Image(type="numpy", label="·∫¢nh X-quang ƒë·∫ßu v√†o")
            
            mode_selector = gr.Dropdown(
                choices=["ROI Extract", "Segment"],
                value="ROI Extract",
                label="Ch·ªçn Ch·∫ø ƒë·ªô X·ª≠ l√Ω"
            )
            
            model_selector = gr.Dropdown(
                choices=["ResNet50", "VGG16"],
                value="ResNet50",
                label="Ch·ªçn M√¥ h√¨nh Ph√¢n lo·∫°i"
            )
            
            submit_btn = gr.Button("Ch·∫°y Ph√¢n T√≠ch", variant="primary")

        # C·ªôt b√™n ph·∫£i cho output
        with gr.Column(scale=2):
            gr.Markdown("### K·∫øt qu·∫£ x·ª≠ l√Ω")
            with gr.Row():
                # output_raw = gr.Image(label="·∫¢nh G·ªëc (Raw)")
                # output_processed = gr.Image(label="·∫¢nh ƒë√£ x·ª≠ l√Ω (ROI/Detect/Segment)")
                # output_for_classify = gr.Image(label="·∫¢nh ƒë∆∞a v√†o ph√¢n lo·∫°i")
                rois_draw = gr.Image(label="·∫¢nh sau khi ROI")
                
            with gr.Row():
                with gr.Column(scale=1):
                    transformed_image_1 = gr.Image(label="·∫¢nh sau khi x·ª≠ l√Ω")
                with gr.Column(scale=2):
                    result_1 = gr.Label(label="K·∫øt qu·∫£ Ph√¢n lo·∫°i")
                    
            with gr.Row():
                with gr.Column(scale=1):
                    transformed_image_2 = gr.Image(label="·∫¢nh sau khi x·ª≠ l√Ω")
                with gr.Column(scale=2):
                    result_2 = gr.Label(label="K·∫øt qu·∫£ Ph√¢n lo·∫°i")

    # K·∫øt n·ªëi h√†nh ƒë·ªông click n√∫t v·ªõi h√†m x·ª≠ l√Ω
    submit_btn.click(
        fn=process_and_classify,
        inputs=[input_image, mode_selector, model_selector],
        outputs=[rois_draw, transformed_image_1, transformed_image_2, result_1, result_2]
    )

    # Th√™m m·ªôt v√†i v√≠ d·ª• ƒë·ªÉ ng∆∞·ªùi d√πng d·ªÖ d√†ng th·ª≠ nghi·ªám
    gr.Examples(
        examples=[
            ["examples/normal.png", "normal"],
            ["examples/osteoporosis.png", "osteoporosis"],
            ["examples/normal_2.png", "normal"],
            ["examples/osteoporosis_2.png", "osteoporosis"],
        ],
        inputs=[input_image, gr.Textbox(label="Nh√£n", show_label=False)],
        outputs=[rois_draw, transformed_image_1, transformed_image_2, result_1, result_2],
        fn=process_and_classify,
        cache_examples=False,
    )

if __name__ == "__main__":
    app.launch(server_name="0.0.0.0", server_port=7860, debug=True, share=True)
    # share=True : th√™m param n√†y n·∫øu mu·ªën ch·∫°y https ng∆∞·ªùi kh√°c c√≥ th·ªÉ truy c·∫≠p trong 1 tu·∫ßn
